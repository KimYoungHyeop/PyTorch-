{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_4_2022_02_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0fEuSrEk1aJvmka6BflRV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dHodL_TmKLzx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_size = 10\n",
        "batch_size = 2\n",
        "input_dim = 3\n",
        "sequence_width = 7\n",
        "data = torch.randn(batch_size, one_hot_size, sequence_width)"
      ],
      "metadata": {
        "id": "Cwr_uTfiLKb-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def describe(x):\n",
        "    print(\"타입: {}\".format(x.type()))\n",
        "    print(\"크기: {}\".format(x.shape))\n",
        "    print(\"값: \\n{}\".format(x))\n",
        "    \n",
        "x_input = torch.rand(batch_size, input_dim)"
      ],
      "metadata": {
        "id": "OYlI0rAHLxYC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 정규화와 Conv1D 층을 사용하여 전체 모델을 다시 만들지 않고 배치 정규화를 사용하는 방법\n",
        "conv1 = nn.Conv1d(in_channels=one_hot_size, out_channels=16, kernel_size=3)\n",
        "conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "\n",
        "conv1_bn = nn.BatchNorm1d(num_features=16)\n",
        "conv2_bn = nn.BatchNorm1d(num_features=32)\n",
        "    \n",
        "intermediate1 = conv1_bn(F.relu(conv1(data)))\n",
        "intermediate2 = conv2_bn(F.relu(conv2(intermediate1)))\n",
        "intermediate3 = conv3(intermediate2)\n",
        "\n",
        "print(intermediate1.size())\n",
        "print(intermediate2.size())\n",
        "print(intermediate3.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLH1bjsXKORZ",
        "outputId": "135550cb-80c0-42f2-b264-ffedae531005"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 5])\n",
            "torch.Size([2, 32, 3])\n",
            "torch.Size([2, 64, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate2.mean(dim=(0, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yskT10JQKfXn",
        "outputId": "0013bf89-1bb7-4300-9adf-9cc9db99f253"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.9868e-08, -5.9605e-08,  0.0000e+00,  9.9341e-09,  3.9736e-08,\n",
              "        -3.9736e-08,  5.9605e-08, -1.9868e-08,  0.0000e+00, -1.9868e-08,\n",
              "         5.9605e-08,  3.9736e-08,  2.4835e-08,  2.9802e-08, -3.9736e-08,\n",
              "         0.0000e+00,  0.0000e+00,  1.9868e-08,  1.9868e-08, -3.9736e-08,\n",
              "        -5.9605e-08, -3.9736e-08, -4.7187e-08,  3.9736e-08, -1.9868e-08,\n",
              "        -3.9736e-08,  5.9605e-08,  0.0000e+00,  9.9341e-09, -9.9341e-09,\n",
              "        -5.9605e-08,  1.9868e-08], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 2, 3, 3)\n",
        "describe(x)\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=2)\n",
        "describe(conv1.weight)\n",
        "describe(conv1(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH6K4L61KfZ_",
        "outputId": "343a82ec-a641-4ccd-de5d-d0f2697c7328"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([1, 2, 3, 3])\n",
            "값: \n",
            "tensor([[[[ 1.3095,  0.3114, -0.8394],\n",
            "          [-0.1989, -0.0737, -0.2197],\n",
            "          [-0.5726, -1.1801, -1.7127]],\n",
            "\n",
            "         [[-1.5674, -0.5867, -0.5012],\n",
            "          [ 1.9722, -1.5392,  0.9853],\n",
            "          [-0.0533,  1.2049, -0.4873]]]])\n",
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([1, 2, 2, 2])\n",
            "값: \n",
            "Parameter containing:\n",
            "tensor([[[[ 0.2955, -0.3012],\n",
            "          [ 0.3498,  0.0460]],\n",
            "\n",
            "         [[-0.2866,  0.1594],\n",
            "          [-0.0418, -0.2972]]]], requires_grad=True)\n",
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([1, 1, 2, 2])\n",
            "값: \n",
            "tensor([[[[ 0.8155,  0.0332],\n",
            "          [-1.5930,  0.1098]]]], grad_fn=<ThnnConv2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 1, 3, 3)\n",
        "describe(x)\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2)\n",
        "describe(conv1.weight)\n",
        "describe(conv1(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0uRs410KfcZ",
        "outputId": "56fac211-0e35-4fdb-c08e-c5ad8d0828bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([1, 1, 3, 3])\n",
            "값: \n",
            "tensor([[[[-1.0513,  0.4397,  0.0934],\n",
            "          [ 0.9385, -1.1628, -1.3089],\n",
            "          [-0.3222, -0.0143,  0.2700]]]])\n",
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([2, 1, 2, 2])\n",
            "값: \n",
            "Parameter containing:\n",
            "tensor([[[[ 0.1827, -0.0588],\n",
            "          [ 0.0472,  0.0615]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4230, -0.3821],\n",
            "          [-0.4528,  0.2168]]]], requires_grad=True)\n",
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([1, 2, 2, 2])\n",
            "값: \n",
            "tensor([[[[ 0.1945,  0.3791],\n",
            "          [ 0.6634,  0.3201]],\n",
            "\n",
            "         [[-1.0843,  0.5986],\n",
            "          [ 1.1895,  0.2787]]]], grad_fn=<ThnnConv2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##요약\n",
        "---\n",
        "두 개의 피드 포워드 신경망 구조를 배웠습니다!  \n",
        "다층 퍼셉트론(MLP 또는 완전 연결 신경망)과 합성곱 신경망(CNN)입니다.\n",
        "\n",
        "어떤 비선형 함수도 근사하는 MLP의 능력을 보았고, 성씨를 토대로 국적을 분류하는 NLP 애플리케이션에 MLP를 적용했습니다. 또 MLP의 주요 단점이자 제약인 파라미터 공유 부족을 배웠고 대안으로 CNN을 소개했습니다. CNN은 매우 효율적으로 구현할 수 있고, 메모리 요구사항이 낮기 때문에 컴퓨터 비전용으로 개발된 CNN은 NLP의 핵심이 되었습니다.\n",
        "\n",
        "패딩, 다일레이션, 스트라이드가 추가된 다양한 합성곱을 배웠고 이들이 어떻게 입력 공간을 변환하는지를 알아보았습니다."
      ],
      "metadata": {
        "id": "xoQ_e7tTMNQM"
      }
    }
  ]
}