{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_4_2022_01_31.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEGJEvfW393Dof0x4XV0lb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b684da3eefd40789f44fd0db7cfefa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e82d00b8003d42f78e43232111b17c9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9002a0e82e8d4d6b88ce9f4def941ecd",
              "IPY_MODEL_d60d9c9a768e481e8b3382cccfe93083",
              "IPY_MODEL_51d0001db56d4d549bc2976aef35324c"
            ]
          }
        },
        "e82d00b8003d42f78e43232111b17c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9002a0e82e8d4d6b88ce9f4def941ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d64f2dfd88574a6a8aaf9489bcbc0fe3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training routine: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68c5cea8d3ea49a993279d8671bf92e5"
          }
        },
        "d60d9c9a768e481e8b3382cccfe93083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1a62e9f85fc407583a728211c09d837",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a37a9ddd86247418fc2cc25feacecec"
          }
        },
        "51d0001db56d4d549bc2976aef35324c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9573a7bad00a496f9e8d376962b73e83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [05:36&lt;00:00,  3.36s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff0163a1332444bfa47bd8c4215d752c"
          }
        },
        "d64f2dfd88574a6a8aaf9489bcbc0fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68c5cea8d3ea49a993279d8671bf92e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1a62e9f85fc407583a728211c09d837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a37a9ddd86247418fc2cc25feacecec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9573a7bad00a496f9e8d376962b73e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff0163a1332444bfa47bd8c4215d752c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f7139ab2a2411f9515b3613a9587a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d54ea55ce38462b829f0bf5d66e24f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5a92c6d4cd9a44b28e15957f26a7b6a6",
              "IPY_MODEL_182300835abd4821a12574045aa73d01",
              "IPY_MODEL_b3b5b4b322944609be6a29a4a764b220"
            ]
          }
        },
        "3d54ea55ce38462b829f0bf5d66e24f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a92c6d4cd9a44b28e15957f26a7b6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1e777b002e640bca23e0d873824b302",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train:  99%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ede0165192e94438a4b574a0a449c002"
          }
        },
        "182300835abd4821a12574045aa73d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa150a94d52947139c389ab479f701c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 120,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 119,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5aa3ae86c2a446a79d4ff8e4298bad96"
          }
        },
        "b3b5b4b322944609be6a29a4a764b220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15ec9b7b2f4843f3a6e01ad28989fdee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 119/120 [05:35&lt;00:03,  3.63s/it, acc=51.8, epoch=99, loss=1.27]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_921e05a23bd647a6a987db5e52af28ad"
          }
        },
        "d1e777b002e640bca23e0d873824b302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ede0165192e94438a4b574a0a449c002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa150a94d52947139c389ab479f701c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5aa3ae86c2a446a79d4ff8e4298bad96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15ec9b7b2f4843f3a6e01ad28989fdee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "921e05a23bd647a6a987db5e52af28ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0dec8bbf76c4b759ae8733bf60d4e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_757b4e9c8272474280399c1610e988e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf3003348827425081caa229101ff46d",
              "IPY_MODEL_f29b308ac18140f2aa4e8c5ef3afe1aa",
              "IPY_MODEL_8e620df276db497bb3adcd60612763b6"
            ]
          }
        },
        "757b4e9c8272474280399c1610e988e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf3003348827425081caa229101ff46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3c1ed9b179d45248a887bc3009f2284",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=val:  96%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5485eb6b78864cb2963f975169b8447d"
          }
        },
        "f29b308ac18140f2aa4e8c5ef3afe1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd6b2ff3d66d40e896d8607566d8f769",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20ec457405c048948831340143563d30"
          }
        },
        "8e620df276db497bb3adcd60612763b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2517b20cee214922b7118e2185fca6b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 24/25 [05:35&lt;00:00,  3.18it/s, acc=45.4, epoch=99, loss=1.81]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf93980e23364a60818ab8d3fd64aed5"
          }
        },
        "a3c1ed9b179d45248a887bc3009f2284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5485eb6b78864cb2963f975169b8447d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd6b2ff3d66d40e896d8607566d8f769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20ec457405c048948831340143563d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2517b20cee214922b7118e2185fca6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf93980e23364a60818ab8d3fd64aed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nqKlm9ooQ64G"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "\n",
        "seed = 1337\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#파이토치를 사용한 MLP\n",
        "\n",
        "class MultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            input_dim (int): 입력 벡터 크기\n",
        "            hidden_dim (int): 첫 번째 Linear 층의 출력 크기\n",
        "            output_dim (int): 두 번째 Linear 층의 출력 크기\n",
        "        \"\"\"\n",
        "        super(MultilayerPerceptron, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"MLP의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, input_dim)입니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n",
        "                크로스-엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape은 (batch, output_dim)입니다.\n",
        "        \"\"\"\n",
        "        intermediate = F.relu(self.fc1(x_in))\n",
        "        output = self.fc2(intermediate)\n",
        "        \n",
        "        if apply_softmax:\n",
        "            output = F.softmax(output, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "HEKVDp1bRJ0-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MLP 객체 생성\n",
        "\n",
        "batch_size = 2 # 한 번에 입력할 샘플 개수\n",
        "input_dim = 3\n",
        "hidden_dim = 100\n",
        "output_dim = 4\n",
        "\n",
        "# 모델 생성\n",
        "mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)\n",
        "print(mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lpIMqVwRK21",
        "outputId": "cf0ab442-ce22-4df5-fd58-3a3045783e81"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptron(\n",
            "  (fc1): Linear(in_features=3, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤한 입력으로 MLP 테스트하기\n",
        "\n",
        "def describe(x):\n",
        "    print(\"타입: {}\".format(x.type()))\n",
        "    print(\"크기: {}\".format(x.shape))\n",
        "    print(\"값: \\n{}\".format(x))"
      ],
      "metadata": {
        "id": "0HvxdLojRK4o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력\n",
        "x_input = torch.rand(batch_size, input_dim)\n",
        "describe(x_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4omH4i-yRK6-",
        "outputId": "4203a3dd-56c1-4fb6-d970-525fd5742a49"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([2, 3])\n",
            "값: \n",
            "tensor([[0.8329, 0.4277, 0.4363],\n",
            "        [0.9686, 0.6316, 0.8494]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_output = mlp(x_input, apply_softmax=False)\n",
        "describe(y_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDEx2azdRK86",
        "outputId": "7184fbd0-1789-4644-a38e-17dc60d2db1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "타입: torch.FloatTensor\n",
            "크기: torch.Size([2, 4])\n",
            "값: \n",
            "tensor([[-0.2456,  0.0723,  0.1589, -0.3294],\n",
            "        [-0.3497,  0.0828,  0.3391, -0.4271]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#예제: 다층 퍼셉트론으로 성씨 분류하기"
      ],
      "metadata": {
        "id": "KS7Xi7pBR0HR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 임포트"
      ],
      "metadata": {
        "id": "ODvWE4hZSDDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "eiFans5ARK-w"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 벡터 변환 클래스"
      ],
      "metadata": {
        "id": "ubOSHtz2SHH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary"
      ],
      "metadata": {
        "id": "bth0K4QFSTdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\" 매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
        "\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
        "            add_unk (bool): UNK 토큰을 추가할지 지정하는 플래그\n",
        "            unk_token (str): Vocabulary에 추가할 UNK 토큰\n",
        "        \"\"\"\n",
        "\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        \n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "        \n",
        "    def to_serializable(self):\n",
        "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
        "        return {'token_to_idx': self._token_to_idx, \n",
        "                'add_unk': self._add_unk, \n",
        "                'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
        "\n",
        "        매개변수:\n",
        "            token (str): Vocabulary에 추가할 토큰\n",
        "        반환값:\n",
        "            index (int): 토큰에 상응하는 정수\n",
        "        \"\"\"\n",
        "        try:\n",
        "            index = self._token_to_idx[token]\n",
        "        except KeyError:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens):\n",
        "        \"\"\" 토큰 리스트를 Vocabulary에 추가합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            tokens (list): 문자열 토큰 리스트\n",
        "        반환값:\n",
        "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
        "        \"\"\"\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
        "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            token (str): 찾을 토큰 \n",
        "        반환값:\n",
        "            index (int): 토큰에 해당하는 인덱스\n",
        "        노트:\n",
        "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
        "            `unk_index`가 0보다 커야 합니다.\n",
        "        \"\"\"\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
        "        \n",
        "        매개변수: \n",
        "            index (int): 찾을 인덱스\n",
        "        반환값:\n",
        "            token (str): 인텍스에 해당하는 토큰\n",
        "        에러:\n",
        "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
        "        \"\"\"\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"Vocabulary에 인덱스(%d)가 없습니다.\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)"
      ],
      "metadata": {
        "id": "egczg5BhRJ3X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizer"
      ],
      "metadata": {
        "id": "2MqjJniPSaxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameVectorizer(object):\n",
        "    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n",
        "    def __init__(self, surname_vocab, nationality_vocab):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            surname_vocab (Vocabulary): 문자를 정수에 매핑하는 Vocabulary 객체\n",
        "            nationality_vocab (Vocabulary): 국적을 정수에 매핑하는 Vocabulary 객체\n",
        "        \"\"\"\n",
        "        self.surname_vocab = surname_vocab\n",
        "        self.nationality_vocab = nationality_vocab\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        \"\"\" 성씨에 대한 원-핫 벡터를 만듭니다\n",
        "\n",
        "        매개변수:\n",
        "            surname (str): 성씨\n",
        "        반환값:\n",
        "            one_hot (np.ndarray): 원-핫 벡터\n",
        "        \"\"\"\n",
        "        vocab = self.surname_vocab\n",
        "        one_hot = np.zeros(len(vocab), dtype=np.float32)\n",
        "        for token in surname:\n",
        "            one_hot[vocab.lookup_token(token)] = 1\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, surname_df):\n",
        "        \"\"\" 데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 성씨 데이터셋\n",
        "        반환값:\n",
        "            SurnameVectorizer 객체\n",
        "        \"\"\"\n",
        "        surname_vocab = Vocabulary(unk_token=\"@\")\n",
        "        nationality_vocab = Vocabulary(add_unk=False)\n",
        "\n",
        "        for index, row in surname_df.iterrows():\n",
        "            for letter in row.surname:\n",
        "                surname_vocab.add_token(letter)\n",
        "            nationality_vocab.add_token(row.nationality)\n",
        "\n",
        "        return cls(surname_vocab, nationality_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        surname_vocab = Vocabulary.from_serializable(contents['surname_vocab'])\n",
        "        nationality_vocab =  Vocabulary.from_serializable(contents['nationality_vocab'])\n",
        "        return cls(surname_vocab=surname_vocab, nationality_vocab=nationality_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'surname_vocab': self.surname_vocab.to_serializable(),\n",
        "                'nationality_vocab': self.nationality_vocab.to_serializable()}"
      ],
      "metadata": {
        "id": "VO25MD_vRJ5u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "h4-PbfabSgra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "    def __init__(self, surname_df, vectorizer):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            surname_df (pandas.DataFrame): 데이터셋\n",
        "            vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        \"\"\"\n",
        "        self.surname_df = surname_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self.train_df = self.surname_df[self.surname_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.surname_df[self.surname_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.surname_df[self.surname_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
        "                             'val': (self.val_df, self.validation_size),\n",
        "                             'test': (self.test_df, self.test_size)}\n",
        "\n",
        "        self.set_split('train')\n",
        "        \n",
        "        # 클래스 가중치\n",
        "        class_counts = surname_df.nationality.value_counts().to_dict()\n",
        "        def sort_key(item):\n",
        "            return self._vectorizer.nationality_vocab.lookup_token(item[0])\n",
        "        sorted_counts = sorted(class_counts.items(), key=sort_key)\n",
        "        frequencies = [count for _, count in sorted_counts]\n",
        "        self.class_weights = 1.0 / torch.tensor(frequencies, dtype=torch.float32)\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, surname_csv):\n",
        "        \"\"\" 데이터셋을 로드하고 새로운 SurnameVectorizer 객체를 만듭니다\n",
        "        \n",
        "        매개변수:\n",
        "            review_csv (str): 데이터셋의 위치\n",
        "        반환값:\n",
        "            SurnameDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        train_surname_df = surname_df[surname_df.split=='train']\n",
        "        return cls(surname_df, SurnameVectorizer.from_dataframe(train_surname_df))\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, surname_csv, vectorizer_filepath):\n",
        "        \"\"\"데이터셋을 로드하고 새로운 SurnameVectorizer 객체를 만듭니다.\n",
        "        캐시된 SurnameVectorizer 객체를 재사용할 때 사용합니다.\n",
        "        \n",
        "        매개변수:\n",
        "            surname_csv (str): 데이터셋의 위치\n",
        "            vectorizer_filepath (str): SurnameVectorizer 객체의 저장 위치\n",
        "        반환값:\n",
        "            SurnameDataset의 인스턴스\n",
        "        \"\"\"\n",
        "        surname_df = pd.read_csv(surname_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(surname_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        \"\"\"파일에서 SurnameVectorizer 객체를 로드하는 정적 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): 직렬화된 SurnameVectorizer 객체의 위치\n",
        "        반환값:\n",
        "            SurnameVectorizer의 인스턴스\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        \"\"\" SurnameVectorizer 객체를 json 형태로 디스크에 저장합니다\n",
        "        \n",
        "        매개변수:\n",
        "            vectorizer_filepath (str): SurnameVectorizer 객체의 저장 위치\n",
        "        \"\"\"\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\" 벡터 변환 객체를 반환합니다 \"\"\"\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" 데이터프레임에 있는 열을 사용해 분할 세트를 선택합니다 \n",
        "        \n",
        "        매개변수:\n",
        "            split (str): \"train\", \"val\", \"test\" 중 하나\n",
        "        \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" 파이토치 데이터셋의 주요 진입 메서드\n",
        "        \n",
        "        매개변수:\n",
        "            index (int): 데이터 포인트의 인덱스\n",
        "        반환값:\n",
        "            데이터 포인트의 특성(x_surname)과 레이블(y_nationality)로 이루어진 딕셔너리\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        surname_vector = \\\n",
        "            self._vectorizer.vectorize(row.surname)\n",
        "\n",
        "        nationality_index = \\\n",
        "            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
        "\n",
        "        return {'x_surname': surname_vector,\n",
        "                'y_nationality': nationality_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\" 배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다\n",
        "        \n",
        "        매개변수:\n",
        "            batch_size (int)\n",
        "        반환값:\n",
        "            배치 개수\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size\n",
        "\n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"): \n",
        "    \"\"\"\n",
        "    파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
        "    걱 텐서를 지정된 장치로 이동합니다.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict"
      ],
      "metadata": {
        "id": "VKHh9gvXRJ8P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델: SurnameClassifier"
      ],
      "metadata": {
        "id": "TpW-X10nSlTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameClassifier(nn.Module):\n",
        "    \"\"\" 성씨 분류를 위한 다층 퍼셉트론 \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        매개변수:\n",
        "            input_dim (int): 입력 벡터 크기\n",
        "            hidden_dim (int): 첫 번째 Linear 층의 출력 크기\n",
        "            output_dim (int): 두 번째 Linear 층의 출력 크기\n",
        "        \"\"\"\n",
        "        super(SurnameClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x_in, apply_softmax=False):\n",
        "        \"\"\"MLP의 정방향 계산\n",
        "        \n",
        "        매개변수:\n",
        "            x_in (torch.Tensor): 입력 데이터 텐서\n",
        "                x_in.shape는 (batch, input_dim)입니다.\n",
        "            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n",
        "                크로스-엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n",
        "        반환값:\n",
        "            결과 텐서. tensor.shape은 (batch, output_dim)입니다.\n",
        "        \"\"\"\n",
        "        intermediate_vector = F.relu(self.fc1(x_in))\n",
        "        prediction_vector = self.fc2(intermediate_vector)\n",
        "\n",
        "        if apply_softmax:\n",
        "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
        "\n",
        "        return prediction_vector"
      ],
      "metadata": {
        "id": "ckMC4TARRJ-V"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 훈련\n",
        "\n",
        "\n",
        "### 헬퍼 함수"
      ],
      "metadata": {
        "id": "h3hhABGCSwjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_state(args):\n",
        "    return {'stop_early': False,\n",
        "            'early_stopping_step': 0,\n",
        "            'early_stopping_best_val': 1e8,\n",
        "            'learning_rate': args.learning_rate,\n",
        "            'epoch_index': 0,\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'test_loss': -1,\n",
        "            'test_acc': -1,\n",
        "            'model_filename': args.model_state_file}\n",
        "\n",
        "def update_train_state(args, model, train_state):\n",
        "    \"\"\" 훈련 상태를 업데이트합니다.\n",
        "\n",
        "    Components:\n",
        "     - 조기 종료: 과대 적합 방지\n",
        "     - 모델 체크포인트: 더 나은 모델을 저장합니다\n",
        "\n",
        "    :param args: 메인 매개변수\n",
        "    :param model: 훈련할 모델\n",
        "    :param train_state: 훈련 상태를 담은 딕셔너리\n",
        "    :returns:\n",
        "        새로운 훈련 상태\n",
        "    \"\"\"\n",
        "\n",
        "    # 적어도 한 번 모델을 저장합니다\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "        train_state['stop_early'] = False\n",
        "\n",
        "    # 성능이 향상되면 모델을 저장합니다\n",
        "    elif train_state['epoch_index'] >= 1:\n",
        "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
        "\n",
        "        # 손실이 나빠지면\n",
        "        if loss_t >= train_state['early_stopping_best_val']:\n",
        "            # 조기 종료 단계 업데이트\n",
        "            train_state['early_stopping_step'] += 1\n",
        "        # 손실이 감소하면\n",
        "        else:\n",
        "            # 최상의 모델 저장\n",
        "            if loss_t < train_state['early_stopping_best_val']:\n",
        "                torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "            # 조기 종료 단계 재설정\n",
        "            train_state['early_stopping_step'] = 0\n",
        "\n",
        "        # 조기 종료 여부 확인\n",
        "        train_state['stop_early'] = \\\n",
        "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
        "\n",
        "    return train_state\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    _, y_pred_indices = y_pred.max(dim=1)\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100"
      ],
      "metadata": {
        "id": "VO5tQa5HRKAg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 유틸리티"
      ],
      "metadata": {
        "id": "JLr74YE5S3lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed_everywhere(seed, cuda):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def handle_dirs(dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)"
      ],
      "metadata": {
        "id": "CskrczLnRKCv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 설정"
      ],
      "metadata": {
        "id": "xJ-PPIp6S8xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Namespace(\n",
        "    # 날짜와 경로 정보\n",
        "    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n",
        "    vectorizer_file=\"vectorizer.json\",\n",
        "    model_state_file=\"model.pth\",\n",
        "    save_dir=\"model_storage/ch4/surname_mlp\",\n",
        "    # 모델 하이퍼파라미터\n",
        "    hidden_dim=300,\n",
        "    # 훈련 하이퍼파라미터\n",
        "    seed=1337,\n",
        "    num_epochs=100,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=64,\n",
        "    # 실행 옵션\n",
        "    cuda=False,\n",
        "    reload_from_files=False,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        ")\n",
        "\n",
        "if args.expand_filepaths_to_save_dir:\n",
        "    args.vectorizer_file = os.path.join(args.save_dir,\n",
        "                                        args.vectorizer_file)\n",
        "\n",
        "    args.model_state_file = os.path.join(args.save_dir,\n",
        "                                         args.model_state_file)\n",
        "    \n",
        "    print(\"파일 경로: \")\n",
        "    print(\"\\t{}\".format(args.vectorizer_file))\n",
        "    print(\"\\t{}\".format(args.model_state_file))\n",
        "    \n",
        "# CUDA 체크\n",
        "if not torch.cuda.is_available():\n",
        "    args.cuda = False\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "    \n",
        "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
        "\n",
        "# 재현성을 위해 시드 설정\n",
        "set_seed_everywhere(args.seed, args.cuda)\n",
        "\n",
        "# 디렉토리 처리\n",
        "handle_dirs(args.save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTWhZ27ORKE6",
        "outputId": "02bcc10d-0115-461f-d5ec-2ca9ef991c99"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일 경로: \n",
            "\tmodel_storage/ch4/surname_mlp/vectorizer.json\n",
            "\tmodel_storage/ch4/surname_mlp/model.pth\n",
            "CUDA 사용여부: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 초기화"
      ],
      "metadata": {
        "id": "28Ct3E-aTDKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 만약 코랩에서 실행하는 경우 아래 코드를 실행하여 전처리된 라이트 버전의 데이터를 다운로드하세요.\n",
        "!mkdir data\n",
        "!wget https://git.io/JtaFp -O data/download.py\n",
        "!wget https://git.io/Jtabe -O data/get-all-data.sh\n",
        "!chmod 755 data/get-all-data.sh\n",
        "%cd data\n",
        "!./get-all-data.sh\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXrOrE-RKHh",
        "outputId": "f5c9b13d-ce08-4ac2-f323-8b61c6e0e7da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2022-01-31 08:55:17--  https://git.io/JtaFp\n",
            "Resolving git.io (git.io)... 18.205.36.100, 52.204.242.176, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|18.205.36.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/download.py [following]\n",
            "--2022-01-31 08:55:17--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1572 (1.5K) [text/plain]\n",
            "Saving to: ‘data/download.py’\n",
            "\n",
            "data/download.py    100%[===================>]   1.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-31 08:55:17 (24.6 MB/s) - ‘data/download.py’ saved [1572/1572]\n",
            "\n",
            "--2022-01-31 08:55:17--  https://git.io/Jtabe\n",
            "Resolving git.io (git.io)... 18.205.36.100, 52.204.242.176, 54.157.58.70, ...\n",
            "Connecting to git.io (git.io)|18.205.36.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/get-all-data.sh [following]\n",
            "--2022-01-31 08:55:18--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/chapter_4/4_2_mlp_surnames/data/get-all-data.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 507 [text/plain]\n",
            "Saving to: ‘data/get-all-data.sh’\n",
            "\n",
            "data/get-all-data.s 100%[===================>]     507  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-31 08:55:18 (30.0 MB/s) - ‘data/get-all-data.sh’ saved [507/507]\n",
            "\n",
            "/content/data\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if args.reload_from_files:\n",
        "    # 체크포인트에서 훈련을 다시 시작\n",
        "    print(\"로딩!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv,\n",
        "                                                              args.vectorizer_file)\n",
        "else:\n",
        "    # 데이터셋과 Vectorizer 만들기\n",
        "    print(\"새로 만들기!\")\n",
        "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
        "    dataset.save_vectorizer(args.vectorizer_file)\n",
        "    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab), \n",
        "                               hidden_dim=args.hidden_dim, \n",
        "                               output_dim=len(vectorizer.nationality_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq_8UC7lRKLh",
        "outputId": "999f62c6-d354-4c2e-f47e-43b91e270282"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "새로 만들기!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련 반복"
      ],
      "metadata": {
        "id": "QVsZo2YoTHMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "\n",
        "    \n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "\n",
        "train_state = make_train_state(args)\n",
        "\n",
        "epoch_bar = tqdm.notebook.tqdm(desc='training routine', \n",
        "                               total=args.num_epochs,\n",
        "                               position=0)\n",
        "\n",
        "dataset.set_split('train')\n",
        "train_bar = tqdm.notebook.tqdm(desc='split=train',\n",
        "                               total=dataset.get_num_batches(args.batch_size), \n",
        "                               position=1, \n",
        "                               leave=True)\n",
        "dataset.set_split('val')\n",
        "val_bar = tqdm.notebook.tqdm(desc='split=val',\n",
        "                             total=dataset.get_num_batches(args.batch_size), \n",
        "                             position=1, \n",
        "                             leave=True)\n",
        "\n",
        "try:\n",
        "    for epoch_index in range(args.num_epochs):\n",
        "        train_state['epoch_index'] = epoch_index\n",
        "\n",
        "        # 훈련 세트에 대한 순회\n",
        "\n",
        "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('train')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        classifier.train()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # 훈련 과정은 5단계로 이루어집니다\n",
        "\n",
        "            # --------------------------------------\n",
        "            # 단계 1. 그레이디언트를 0으로 초기화합니다\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 단계 2. 출력을 계산합니다\n",
        "            y_pred = classifier(batch_dict['x_surname'])\n",
        "\n",
        "            # 단계 3. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 4. 손실을 사용해 그레이디언트를 계산합니다\n",
        "            loss.backward()\n",
        "\n",
        "            # 단계 5. 옵티마이저로 가중치를 업데이트합니다\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "\n",
        "            # 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "            # 진행 바 업데이트\n",
        "            train_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            train_bar.update()\n",
        "\n",
        "        train_state['train_loss'].append(running_loss)\n",
        "        train_state['train_acc'].append(running_acc)\n",
        "\n",
        "        # 검증 세트에 대한 순회\n",
        "\n",
        "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
        "        dataset.set_split('val')\n",
        "        batch_generator = generate_batches(dataset, \n",
        "                                           batch_size=args.batch_size, \n",
        "                                           device=args.device)\n",
        "        running_loss = 0.\n",
        "        running_acc = 0.\n",
        "        classifier.eval()\n",
        "\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "\n",
        "            # 단계 1. 출력을 계산합니다\n",
        "            y_pred =  classifier(batch_dict['x_surname'])\n",
        "\n",
        "            # 단계 2. 손실을 계산합니다\n",
        "            loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "            loss_t = loss.to(\"cpu\").item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            # 단계 3. 정확도를 계산합니다\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            val_bar.set_postfix(loss=running_loss, acc=running_acc, \n",
        "                            epoch=epoch_index)\n",
        "            val_bar.update()\n",
        "\n",
        "        train_state['val_loss'].append(running_loss)\n",
        "        train_state['val_acc'].append(running_acc)\n",
        "\n",
        "        train_state = update_train_state(args=args, model=classifier,\n",
        "                                         train_state=train_state)\n",
        "\n",
        "        scheduler.step(train_state['val_loss'][-1])\n",
        "\n",
        "        if train_state['stop_early']:\n",
        "            break\n",
        "\n",
        "        train_bar.n = 0\n",
        "        val_bar.n = 0\n",
        "        epoch_bar.update()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Exiting loop\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4b684da3eefd40789f44fd0db7cfefa2",
            "e82d00b8003d42f78e43232111b17c9a",
            "9002a0e82e8d4d6b88ce9f4def941ecd",
            "d60d9c9a768e481e8b3382cccfe93083",
            "51d0001db56d4d549bc2976aef35324c",
            "d64f2dfd88574a6a8aaf9489bcbc0fe3",
            "68c5cea8d3ea49a993279d8671bf92e5",
            "a1a62e9f85fc407583a728211c09d837",
            "4a37a9ddd86247418fc2cc25feacecec",
            "9573a7bad00a496f9e8d376962b73e83",
            "ff0163a1332444bfa47bd8c4215d752c",
            "e2f7139ab2a2411f9515b3613a9587a3",
            "3d54ea55ce38462b829f0bf5d66e24f3",
            "5a92c6d4cd9a44b28e15957f26a7b6a6",
            "182300835abd4821a12574045aa73d01",
            "b3b5b4b322944609be6a29a4a764b220",
            "d1e777b002e640bca23e0d873824b302",
            "ede0165192e94438a4b574a0a449c002",
            "fa150a94d52947139c389ab479f701c3",
            "5aa3ae86c2a446a79d4ff8e4298bad96",
            "15ec9b7b2f4843f3a6e01ad28989fdee",
            "921e05a23bd647a6a987db5e52af28ad",
            "b0dec8bbf76c4b759ae8733bf60d4e72",
            "757b4e9c8272474280399c1610e988e4",
            "cf3003348827425081caa229101ff46d",
            "f29b308ac18140f2aa4e8c5ef3afe1aa",
            "8e620df276db497bb3adcd60612763b6",
            "a3c1ed9b179d45248a887bc3009f2284",
            "5485eb6b78864cb2963f975169b8447d",
            "dd6b2ff3d66d40e896d8607566d8f769",
            "20ec457405c048948831340143563d30",
            "2517b20cee214922b7118e2185fca6b6",
            "cf93980e23364a60818ab8d3fd64aed5"
          ]
        },
        "id": "-WiT9mZ8RKNm",
        "outputId": "22f08909-39cc-448e-961a-35e952858156"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b684da3eefd40789f44fd0db7cfefa2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training routine:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f7139ab2a2411f9515b3613a9587a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train:   0%|          | 0/120 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0dec8bbf76c4b759ae8733bf60d4e72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=val:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 좋은 모델을 사용해 테스트 세트의 손실과 정확도를 계산합니다\n",
        "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
        "\n",
        "classifier = classifier.to(args.device)\n",
        "dataset.class_weights = dataset.class_weights.to(args.device)\n",
        "loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # 출력을 계산합니다\n",
        "    y_pred =  classifier(batch_dict['x_surname'])\n",
        "    \n",
        "    # 손실을 계산합니다\n",
        "    loss = loss_func(y_pred, batch_dict['y_nationality'])\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # 정확도를 계산합니다\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_nationality'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "train_state['test_loss'] = running_loss\n",
        "train_state['test_acc'] = running_acc"
      ],
      "metadata": {
        "id": "PMNm-YtTRKP3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"테스트 손실: {};\".format(train_state['test_loss']))\n",
        "print(\"테스트 정확도: {}\".format(train_state['test_acc']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhngpMYLRKSM",
        "outputId": "54aa7818-2285-4190-fa8f-97564154cb6d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 손실: 1.783166947364807;\n",
            "테스트 정확도: 46.31249999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 추론"
      ],
      "metadata": {
        "id": "tsfNkyDGTPss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_nationality(surname, classifier, vectorizer):\n",
        "    \"\"\"새로운 성씨로 국적 예측하기\n",
        "    \n",
        "    매개변수:\n",
        "        surname (str): 분류할 성씨\n",
        "        classifier (SurnameClassifer): 분류기 객체\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "    반환값:\n",
        "        가장 가능성이 높은 국적과 확률로 구성된 딕셔너리\n",
        "    \"\"\"\n",
        "    vectorized_surname = vectorizer.vectorize(surname)\n",
        "    vectorized_surname = torch.tensor(vectorized_surname).view(1, -1)\n",
        "    result = classifier(vectorized_surname, apply_softmax=True)\n",
        "\n",
        "    probability_values, indices = result.max(dim=1)\n",
        "    index = indices.item()\n",
        "\n",
        "    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "    probability_value = probability_values.item()\n",
        "\n",
        "    return {'nationality': predicted_nationality, 'probability': probability_value}"
      ],
      "metadata": {
        "id": "T7X1w0FiRKUU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_surname = input(\"분류하려는 성씨를 입력하세요: \")\n",
        "classifier = classifier.to(\"cpu\")\n",
        "prediction = predict_nationality(new_surname, classifier, vectorizer)\n",
        "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
        "                                    prediction['nationality'],\n",
        "                                    prediction['probability']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4R9hXYlRKYn",
        "outputId": "1bdb7ac4-a592-49ea-b02e-9e716efa96ae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류하려는 성씨를 입력하세요: issac\n",
            "issac -> Italian (p=0.41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최상위 K개 예측"
      ],
      "metadata": {
        "id": "MQfelDd6TSY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.nationality_vocab.lookup_index(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bFtiBQ7oTYPr",
        "outputId": "4c478675-3d95-40d2-83dd-5b5767987baf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Irish'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_topk_nationality(name, classifier, vectorizer, k=5):\n",
        "    \"\"\"새로운 성씨에 대한 최상위 K개 국적을 예측합니다\n",
        "    \n",
        "    매개변수:\n",
        "        surname (str): 분류하려는 성씨\n",
        "        classifier (SurnameClassifer): 분류기 객체\n",
        "        vectorizer (SurnameVectorizer): SurnameVectorizer 객체\n",
        "        k (int): the number of top nationalities to return\n",
        "    반환값:\n",
        "        딕셔너리 리스트, 각 딕셔너리는 국적과 확률로 구성됩니다.\n",
        "    \"\"\"\n",
        "    vectorized_name = vectorizer.vectorize(name)\n",
        "    vectorized_name = torch.tensor(vectorized_name).view(1, -1)\n",
        "    prediction_vector = classifier(vectorized_name, apply_softmax=True)\n",
        "    probability_values, indices = torch.topk(prediction_vector, k=k)\n",
        "    \n",
        "    # 반환되는 크기는 (1,k)입니다\n",
        "    probability_values = probability_values.detach().numpy()[0]\n",
        "    indices = indices.detach().numpy()[0]\n",
        "    \n",
        "    results = []\n",
        "    for prob_value, index in zip(probability_values, indices):\n",
        "        nationality = vectorizer.nationality_vocab.lookup_index(index)\n",
        "        results.append({'nationality': nationality, \n",
        "                        'probability': prob_value})\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "new_surname = input(\"분류하려는 성씨를 입력하세요: \")\n",
        "classifier = classifier.to(\"cpu\")\n",
        "\n",
        "k = int(input(\"얼마나 많은 예측을 보고 싶나요? \"))\n",
        "if k > len(vectorizer.nationality_vocab):\n",
        "    print(\"앗! 전체 국적 개수보다 큰 값을 입력했습니다. 모든 국적에 대한 예측을 반환합니다. :)\")\n",
        "    k = len(vectorizer.nationality_vocab)\n",
        "    \n",
        "predictions = predict_topk_nationality(new_surname, classifier, vectorizer, k=k)\n",
        "\n",
        "print(\"최상위 {}개 예측:\".format(k))\n",
        "print(\"===================\")\n",
        "for prediction in predictions:\n",
        "    print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
        "                                        prediction['nationality'],\n",
        "                                        prediction['probability']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm5pYe4OTYSC",
        "outputId": "dd7b5215-4e7c-4ec1-e748-ebcce59433a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "분류하려는 성씨를 입력하세요: Winston\n",
            "얼마나 많은 예측을 보고 싶나요? 15\n",
            "최상위 15개 예측:\n",
            "===================\n",
            "Winston -> Scottish (p=0.76)\n",
            "Winston -> English (p=0.16)\n",
            "Winston -> German (p=0.03)\n",
            "Winston -> Polish (p=0.03)\n",
            "Winston -> Greek (p=0.01)\n",
            "Winston -> Czech (p=0.01)\n",
            "Winston -> Italian (p=0.00)\n",
            "Winston -> French (p=0.00)\n",
            "Winston -> Spanish (p=0.00)\n",
            "Winston -> Japanese (p=0.00)\n",
            "Winston -> Russian (p=0.00)\n",
            "Winston -> Irish (p=0.00)\n",
            "Winston -> Portuguese (p=0.00)\n",
            "Winston -> Dutch (p=0.00)\n",
            "Winston -> Arabic (p=0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yiqx9iWqTYUg"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}