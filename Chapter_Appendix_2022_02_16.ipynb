{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_Appendix_2022_02_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/Q21LP4cgd4MzWNIu0tQx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# pororo를 사용한 한글 자연어 처리"
      ],
      "metadata": {
        "id": "D3To_6Ln_zLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2021년 초에 카카오브레인([https://www.kakaobrain.com/](https://www.kakaobrain.com/))에서 다양한 한글 자연어 처리 작업을 위한 `pororo`('뽀로로'라고 읽습니다)([https://github.com/kakaobrain/pororo](https://github.com/kakaobrain/pororo)) 파이썬 라이브러리를 릴리스했습니다. `pororo` 라이브러리는 BERT, Transformer 등 파이토치로 구현된 최신 NLP 모델을 사용해 30여 가지의 자연어 처리 작업을 수행합니다. 여기에서는 이 중에 대표적인 몇 가지 작업에 대해서 알아 보겠습니다. `pororo` 라이브러리가 수행할 수 있는 전체 작업 목록은 온라인 문서([https://kakaobrain.github.io/pororo/index.html](https://kakaobrain.github.io/pororo/index.html))를 참고하세요.\n",
        "\n",
        "`pororo`라이브러리는 `pip` 명령으로 간단히 설치할 수 있습니다. 현재는 파이썬 3.6 버전 이상과 파이토치 1.6 버전(CUDA 10.1)을 지원합니다."
      ],
      "metadata": {
        "id": "UMdLbXeQ_zNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pororo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O34swZyrAG4I",
        "outputId": "df52bb17-a9f6-46e8-edcb-b940d6bdeccc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pororo\n",
            "  Downloading pororo-0.4.2-py3-none-any.whl (256 kB)\n",
            "\u001b[K     |████████████████████████████████| 256 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting fairseq>=0.10.2\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pororo) (4.2.6)\n",
            "Collecting marisa-trie\n",
            "  Downloading marisa_trie-0.7.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from pororo) (7.1.2)\n",
            "Collecting word2word\n",
            "  Downloading word2word-1.0.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pororo) (1.1.0)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 43.8 MB/s \n",
            "\u001b[?25hCollecting kss\n",
            "  Downloading kss-3.4.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 32.7 MB/s \n",
            "\u001b[?25hCollecting nltk>=3.5\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 52.4 MB/s \n",
            "\u001b[?25hCollecting g2p-en\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 28.8 MB/s \n",
            "\u001b[?25hCollecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting sentence-transformers>=0.4.1.2\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->pororo) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->pororo) (0.16.0)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq>=0.10.2->pororo) (4.62.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq>=0.10.2->pororo) (2019.12.20)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq>=0.10.2->pororo) (1.15.0)\n",
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq>=0.10.2->pororo) (0.29.27)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.5->pororo) (7.1.2)\n",
            "Collecting regex\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 40.3 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq>=0.10.2->pororo) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1.2->pororo) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1.2->pororo) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->pororo) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->pororo) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->pororo) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->pororo) (3.4.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->sentence-transformers>=0.4.1.2->pororo) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.0.0->pororo) (3.0.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq>=0.10.2->pororo) (2.21)\n",
            "Collecting distance>=0.1.3\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from g2p-en->pororo) (2.1.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq>=0.10.2->pororo) (5.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.0.0->pororo) (3.7.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 76.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from marisa-trie->pororo) (57.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->pororo) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->pororo) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->pororo) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->pororo) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->pororo) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers>=0.4.1.2->pororo) (3.1.0)\n",
            "Building wheels for collected packages: sentence-transformers, distance, antlr4-python3-runtime, kss, emoji, wget\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=b8995b98d29433a64b777b51071b5de759ac9441f889cececcb8769aa9ce50ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16276 sha256=ee677ecd1bf958a01e12ac7d1f88e5bd015d5d28554210ef1c3ee0667aa1319b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=521c407ae4a82fe03a71b3b0dddc6f62f6d5a9a98cbe1638db4efc7d9ecdf698\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4-py3-none-any.whl size=42449209 sha256=fb1692951e0f9184f779f0349923c26f989f680dbee4915e77ee3d0915a7e01e\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/8e/5b/305f0a804fba3943f353f1b0e3cb1fad39e4f5ae4893ea9590\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=9a6a41060a60f3dafc3b520fac745c02623f951ccd9731733339ff737537b012\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=4857884e53ceaca183e36f74740022547990b966156c8bb04a42948883297c52\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built sentence-transformers distance antlr4-python3-runtime kss emoji wget\n",
            "Installing collected packages: regex, pyyaml, antlr4-python3-runtime, torch, tokenizers, sacremoses, portalocker, omegaconf, huggingface-hub, colorama, wget, transformers, torchvision, sentencepiece, sacrebleu, nltk, hydra-core, emoji, distance, dataclasses, word2word, whoosh, sentence-transformers, marisa-trie, kss, g2p-en, fairseq, pororo\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.8 colorama-0.4.4 dataclasses-0.6 distance-0.1.3 emoji-1.6.3 fairseq-0.10.2 g2p-en-2.1.0 huggingface-hub-0.4.0 hydra-core-1.1.1 kss-3.4 marisa-trie-0.7.7 nltk-3.7 omegaconf-2.1.1 pororo-0.4.2 portalocker-2.3.2 pyyaml-6.0 regex-2022.1.18 sacrebleu-2.0.0 sacremoses-0.0.47 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.5 torch-1.6.0 torchvision-0.7.0 transformers-4.16.2 wget-3.2 whoosh-2.7.4 word2word-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pororo`를 사용하는 방법은 `Pororo` 클래스에 원하는 작업을 지정하여 작업에 맞는 클래스 객체를 얻는 것입니다. 전체 작업 목록은 온라인 문서에 있으며 다음과 같이 `available_tasks()` 메서드를 호출하여 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "k6BNrr5E_zPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pororo import Pororo\n",
        "\n",
        "Pororo.available_tasks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GSPE8HEmARKf",
        "outputId": "9d226f24-b2f8-4c6d-ce1e-bb365a3f50a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Available tasks are ['mrc', 'rc', 'qa', 'question_answering', 'machine_reading_comprehension', 'reading_comprehension', 'sentiment', 'sentiment_analysis', 'nli', 'natural_language_inference', 'inference', 'fill', 'fill_in_blank', 'fib', 'para', 'pi', 'cse', 'contextual_subword_embedding', 'similarity', 'sts', 'semantic_textual_similarity', 'sentence_similarity', 'sentvec', 'sentence_embedding', 'sentence_vector', 'se', 'inflection', 'morphological_inflection', 'g2p', 'grapheme_to_phoneme', 'grapheme_to_phoneme_conversion', 'w2v', 'wordvec', 'word2vec', 'word_vector', 'word_embedding', 'tokenize', 'tokenise', 'tokenization', 'tokenisation', 'tok', 'segmentation', 'seg', 'mt', 'machine_translation', 'translation', 'pos', 'tag', 'pos_tagging', 'tagging', 'const', 'constituency', 'constituency_parsing', 'cp', 'pg', 'collocation', 'collocate', 'col', 'word_translation', 'wt', 'summarization', 'summarisation', 'text_summarization', 'text_summarisation', 'summary', 'gec', 'review', 'review_scoring', 'lemmatization', 'lemmatisation', 'lemma', 'ner', 'named_entity_recognition', 'entity_recognition', 'zero-topic', 'dp', 'dep_parse', 'caption', 'captioning', 'asr', 'speech_recognition', 'st', 'speech_translation', 'tts', 'text_to_speech', 'speech_synthesis', 'ocr', 'srl', 'semantic_role_labeling', 'p2g', 'aes', 'essay', 'qg', 'question_generation', 'age_suitability', 'wsd']\""
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 광학 문자 인식\n",
        "---\n",
        "먼저 이미지에서 문자를 읽는 광학 문자 인식(Optical Character Recognition) 작업을 수행해 보겠습니다. 광학 문자 인식 작업을 수행하려면 `Pororo` 클래스에 `task='ocr'` 매개변수를 지정하여 객체를 만듭니다."
      ],
      "metadata": {
        "id": "BxZ_z1dMCD45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ocr` 객체를 사용하는 방법은 간단합니다. 문자 인식을 하려는 이미지를 매개변수로 전달하면 됩니다. 다음과 같은 책 표지 이미지를 사용해 보죠."
      ],
      "metadata": {
        "id": "61AJ7yG2CJB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/rickiepark/nlp-with-pytorch/raw/main/ocr-test.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8q-nPbXCA8F",
        "outputId": "bf12b586-ea88-4bfa-a388-bd605fe4b7a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-16 14:55:36--  https://github.com/rickiepark/nlp-with-pytorch/raw/main/ocr-test.png\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/ocr-test.png [following]\n",
            "--2022-02-16 14:55:36--  https://raw.githubusercontent.com/rickiepark/nlp-with-pytorch/main/ocr-test.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11615635 (11M) [application/octet-stream]\n",
            "Saving to: ‘ocr-test.png.1’\n",
            "\n",
            "\rocr-test.png.1        0%[                    ]       0  --.-KB/s               \rocr-test.png.1      100%[===================>]  11.08M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-02-16 14:55:36 (170 MB/s) - ‘ocr-test.png.1’ saved [11615635/11615635]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ocr('ocr-test.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa5z7ARICPhp",
        "outputId": "d08e1cea-7e5e-43fb-fb75-b98db911b660"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Machine Leaming with Python Cookbook 파이썬을 활용한 머신러닝 쿡북',\n",
              " '크리스 알본 지음 빅해선 옮김',\n",
              " \"Introduction to Machine Learning with Pythan 안드레아스 뮐러. 세라 가이도 지음 파이썬 라이브러리를 활용한 머신러닝 번역개정판 '해선 옮김\",\n",
              " 'Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow',\n",
              " \"핸즈온 머신러닝 '] 오렐리앙 제롱 지음 박해선 옮김\",\n",
              " 'GANS 텐서플로 2.x와 케라스로 구축하는 야쿠프 란그르, 블라디미르 보크 지음 GAN 인 액션 생성적 적대 신경망 박해선 옮김 INAGTION',\n",
              " '데이비드 포스터 지음 Generative 미술관에 GAN 딥러닝 실전 프로젝트 Deep Learning 박해선 옮김']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<핸즈온 머신러닝>에서 세로로 쓰여진 '2판'은 인식을 못했고 <GAN 인 액션>과 <미술관에 GAN 딥러닝>은 행을 조금 혼동하고 있지만 전반적으로 높은 인식율을 보여주고 있습니다.\n",
        "\n",
        "광학 문자 인식 작업에 지원하는 언어는 영어와 한국어입니다. 지원하는 언어 목록을 보려면 `pororo` 패키지의 온라인 문서를 참고하세요. 현재는 `Pororo` 클래스에서 가능한 언어를 직접 확인할 수는 없습니다. 다만 다음처럼 `SUPPORTED_TASKS` 딕셔너리에 매핑된 광학 문자 인식 클래스의 `get_available_langs()` 정적 메서드를 호출하여 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "Wry8tLlx_zZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pororo.pororo import SUPPORTED_TASKS\n",
        "\n",
        "SUPPORTED_TASKS['ocr'].get_available_langs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBU-FEIlCXcW",
        "outputId": "ba196c8a-4572-448f-d088-4a7dbd90f9b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['en', 'ko']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로컬에 있는 파일 뿐만 아니라 URL을 전달할 수도 있습니다. 다음과 같이 영어로 쓰여진 표지판([https://bit.ly/london-sign](https://bit.ly/london-sign), Goldflakes, CC BY-SA 4.0)을 인식해 보죠."
      ],
      "metadata": {
        "id": "8ww_pDx8CbYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ocr('https://bit.ly/london-sign', detail=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hjHO30iCVVZ",
        "outputId": "b936b791-040f-471a-ae83-1109bee61884"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rProgress: |--------------------------------------------------| 0.0% Complete\r\rProgress: |--------------------------------------------------| 1.6% Complete\r\rProgress: |█-------------------------------------------------| 3.1% Complete\r\rProgress: |██------------------------------------------------| 4.7% Complete\r\rProgress: |███-----------------------------------------------| 6.2% Complete\r\rProgress: |███-----------------------------------------------| 7.8% Complete\r\rProgress: |████----------------------------------------------| 9.3% Complete\r\rProgress: |█████---------------------------------------------| 10.9% Complete\r\rProgress: |██████--------------------------------------------| 12.4% Complete\r\rProgress: |██████--------------------------------------------| 14.0% Complete\r\rProgress: |███████-------------------------------------------| 15.5% Complete\r\rProgress: |████████------------------------------------------| 17.1% Complete\r\rProgress: |█████████-----------------------------------------| 18.6% Complete\r\rProgress: |██████████----------------------------------------| 20.2% Complete\r\rProgress: |██████████----------------------------------------| 21.7% Complete\r\rProgress: |███████████---------------------------------------| 23.3% Complete\r\rProgress: |████████████--------------------------------------| 24.9% Complete\r\rProgress: |█████████████-------------------------------------| 26.4% Complete\r\rProgress: |█████████████-------------------------------------| 28.0% Complete\r\rProgress: |██████████████------------------------------------| 29.5% Complete\r\rProgress: |███████████████-----------------------------------| 31.1% Complete\r\rProgress: |████████████████----------------------------------| 32.6% Complete\r\rProgress: |█████████████████---------------------------------| 34.2% Complete\r\rProgress: |█████████████████---------------------------------| 35.7% Complete\r\rProgress: |██████████████████--------------------------------| 37.3% Complete\r\rProgress: |███████████████████-------------------------------| 38.8% Complete\r\rProgress: |████████████████████------------------------------| 40.4% Complete\r\rProgress: |████████████████████------------------------------| 41.9% Complete\r\rProgress: |█████████████████████-----------------------------| 43.5% Complete\r\rProgress: |██████████████████████----------------------------| 45.0% Complete\r\rProgress: |███████████████████████---------------------------| 46.6% Complete\r\rProgress: |████████████████████████--------------------------| 48.2% Complete\r\rProgress: |████████████████████████--------------------------| 49.7% Complete\r\rProgress: |█████████████████████████-------------------------| 51.3% Complete\r\rProgress: |██████████████████████████------------------------| 52.8% Complete\r\rProgress: |███████████████████████████-----------------------| 54.4% Complete\r\rProgress: |███████████████████████████-----------------------| 55.9% Complete\r\rProgress: |████████████████████████████----------------------| 57.5% Complete\r\rProgress: |█████████████████████████████---------------------| 59.0% Complete\r\rProgress: |██████████████████████████████--------------------| 60.6% Complete\r\rProgress: |███████████████████████████████-------------------| 62.1% Complete\r\rProgress: |███████████████████████████████-------------------| 63.7% Complete\r\rProgress: |████████████████████████████████------------------| 65.2% Complete\r\rProgress: |█████████████████████████████████-----------------| 66.8% Complete\r\rProgress: |██████████████████████████████████----------------| 68.3% Complete\r\rProgress: |██████████████████████████████████----------------| 69.9% Complete\r\rProgress: |███████████████████████████████████---------------| 71.5% Complete\r\rProgress: |████████████████████████████████████--------------| 73.0% Complete\r\rProgress: |█████████████████████████████████████-------------| 74.6% Complete\r\rProgress: |██████████████████████████████████████------------| 76.1% Complete\r\rProgress: |██████████████████████████████████████------------| 77.7% Complete\r\rProgress: |███████████████████████████████████████-----------| 79.2% Complete\r\rProgress: |████████████████████████████████████████----------| 80.8% Complete\r\rProgress: |█████████████████████████████████████████---------| 82.3% Complete\r\rProgress: |█████████████████████████████████████████---------| 83.9% Complete\r\rProgress: |██████████████████████████████████████████--------| 85.4% Complete\r\rProgress: |███████████████████████████████████████████-------| 87.0% Complete\r\rProgress: |████████████████████████████████████████████------| 88.5% Complete\r\rProgress: |█████████████████████████████████████████████-----| 90.1% Complete\r\rProgress: |█████████████████████████████████████████████-----| 91.7% Complete\r\rProgress: |██████████████████████████████████████████████----| 93.2% Complete\r\rProgress: |███████████████████████████████████████████████---| 94.8% Complete\r\rProgress: |████████████████████████████████████████████████--| 96.3% Complete\r\rProgress: |████████████████████████████████████████████████--| 97.9% Complete\r\rProgress: |█████████████████████████████████████████████████-| 99.4% Complete\r\rProgress: |██████████████████████████████████████████████████| 101.0% Complete\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bounding_poly': [{'description': 'Central London A4 (West End) alternative route for goods vehicles',\n",
              "   'vertices': [{'x': 98, 'y': 68},\n",
              "    {'x': 330, 'y': 68},\n",
              "    {'x': 330, 'y': 182},\n",
              "    {'x': 98, 'y': 182}]},\n",
              "  {'description': '37n',\n",
              "   'vertices': [{'x': 174, 'y': 254},\n",
              "    {'x': 232, 'y': 254},\n",
              "    {'x': 232, 'y': 280},\n",
              "    {'x': 174, 'y': 280}]},\n",
              "  {'description': 'pm 6 am',\n",
              "   'vertices': [{'x': 160, 'y': 328},\n",
              "    {'x': 254, 'y': 328},\n",
              "    {'x': 254, 'y': 356},\n",
              "    {'x': 160, 'y': 356}]},\n",
              "  {'description': 'C. London (Westminster A3220 (A3212)',\n",
              "   'vertices': [{'x': 132, 'y': 380},\n",
              "    {'x': 333, 'y': 380},\n",
              "    {'x': 333, 'y': 469},\n",
              "    {'x': 132, 'y': 469}]}],\n",
              " 'description': ['Central London A4 (West End) alternative route for goods vehicles',\n",
              "  '37n',\n",
              "  'pm 6 am',\n",
              "  'C. London (Westminster A3220 (A3212)']}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과에서 알 수 있듯이 이미지 구역에 따라 인식한 글씨를 나누어 리스트로 반환하고 있습니다. 또한 `detail=True`로 지정하면 인식된 글자 구역의 왼쪽 위에서 시계 방향으로 4개의 사각형 모서리 좌표를 반환합니다. `pororo`의 광학 인식 문자에 사용되는 OCR 모델은 내부 데이터와 AI hub의 한국어 글자체 이미지 AI 데이터([https://www.aihub.or.kr/aidata/133](https://www.aihub.or.kr/aidata/133))을 사용하여 훈련되었습니다."
      ],
      "metadata": {
        "id": "KcX7IPaICiY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RIwOoRf3CVXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}